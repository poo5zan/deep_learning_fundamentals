{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 1: Predict diabetes using Perceptron\n",
    "Student: Pujan Maharjan (a1863495)\n",
    "Course: Deep Learning Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# !pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Perceptron():\n",
    "    def __init__(self, file_path, weights, loss_function_name, learning_rate, epoch) -> None:\n",
    "        self.file_path = file_path\n",
    "        self.weights = weights\n",
    "        self.loss_function_name = loss_function_name\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch = epoch\n",
    "\n",
    "    def get_features_labels_from_file_data(self):\n",
    "        X, y = load_svmlight_file(self.file_path)\n",
    "        # convert X from scipy.sparce.csr.csr_matrix to numpy array\n",
    "        X = X.toarray()\n",
    "        # reshape y from (768,) to (768,1)\n",
    "        y = y.reshape(-1, 1)\n",
    "        return X,y\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(np.dot(X, self.weights))\n",
    "\n",
    "    def zero_one_loss(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        losses = []\n",
    "        # if correct prediction, then loss = 0, else loss = 1\n",
    "        for i in range(len(y)):\n",
    "            if y[i] == predictions[i]:\n",
    "                losses.append(0)\n",
    "            else:\n",
    "                losses.append(1)\n",
    "\n",
    "        return np.array(losses).reshape(-1,1)\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val):\n",
    "        train_data = []\n",
    "        for epoch_number in range(self.epoch):\n",
    "            # print('Epoch number: ', epoch_number)\n",
    "            train_loss = None\n",
    "            validation_loss = None\n",
    "            train_accuracy = None\n",
    "            if (self.loss_function_name == \"zero_one_loss\"):\n",
    "                train_loss = self.zero_one_loss(X_train, y_train)\n",
    "                validation_loss = self.zero_one_loss(X_val, y_val)\n",
    "                \n",
    "                # xl = X_train * train_loss               \n",
    "                # yxl = y_train * xl                \n",
    "                yxlr = self.learning_rate * y_train * X_train * train_loss           \n",
    "                yxlr_sum = np.sum(yxlr, axis=0).reshape(-1,1)                \n",
    "                self.weights = self.weights + yxlr_sum                \n",
    "                train_accuracy = self.accuracy(X_train, y_train)\n",
    "                \n",
    "            validation_accuracy = self.accuracy(X_val, y_val)\n",
    "\n",
    "            train_data.append({\n",
    "                'learning_rate': self.learning_rate, \n",
    "                'epoch': epoch_number, \n",
    "                'train_loss': np.sum(train_loss), \n",
    "                'validation_loss': np.sum(validation_loss),\n",
    "                'validation_accuracy': validation_accuracy,\n",
    "                'train_accuracy': train_accuracy})\n",
    "\n",
    "        # print('Training Completed')\n",
    "        return train_data\n",
    "\n",
    "    def accuracy(self, X_accuracy, y_accuracy):\n",
    "        predictions_for_accuracy = self.predict(X_accuracy)\n",
    "        accuracy_score_from_sk_learn = accuracy_score(y_accuracy, predictions_for_accuracy)\n",
    "        return accuracy_score_from_sk_learn\n",
    "\n",
    "    def split_train_validation_test(self, X, y):\n",
    "        # reference to split (train/validation/test):\n",
    "        #  https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "        # 0.25 * 0.8 = 0.2\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File =  diabetes_scale.txt  test_accuracy =  0.6948051948051948\n",
      "File =  diabetes.txt  test_accuracy =  0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "# 1. Different Files (Without scaling vs scaled)\n",
    "np.random.seed(0)\n",
    "weights = np.random.uniform(low = -1, high = 1, size=8).reshape(-1,1)\n",
    "for file_path in ['diabetes_scale.txt','diabetes.txt']:\n",
    "    perceptron = Perceptron(\n",
    "        file_path=file_path,\n",
    "        weights=weights, \n",
    "        loss_function_name=\"zero_one_loss\", \n",
    "        learning_rate=0.01, \n",
    "        epoch=10)\n",
    "    X, y = perceptron.get_features_labels_from_file_data()\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = perceptron.split_train_validation_test(X, y)\n",
    "    train_data = perceptron.train(X_train, y_train, X_val, y_val)\n",
    "    test_accuracy = perceptron.accuracy(X_test, y_test)\n",
    "    print('File = ', file_path, ' test_accuracy = ', test_accuracy)\n",
    "    # train_data_pd = pd.DataFrame(train_data)\n",
    "    # print(train_data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate =  0.1  test_accuracy =  0.487012987012987\n",
      "Learning Rate =  0.01  test_accuracy =  0.6948051948051948\n",
      "Learning Rate =  0.02  test_accuracy =  0.6948051948051948\n",
      "Learning Rate =  0.028  test_accuracy =  0.7142857142857143\n",
      "Learning Rate =  0.029  test_accuracy =  0.7337662337662337\n",
      "Learning Rate =  0.03  test_accuracy =  0.7077922077922078\n",
      "Learning Rate =  0.033  test_accuracy =  0.6883116883116883\n",
      "Learning Rate =  0.035  test_accuracy =  0.487012987012987\n",
      "Learning Rate =  0.037  test_accuracy =  0.461038961038961\n",
      "Learning Rate =  0.04  test_accuracy =  0.4675324675324675\n",
      "Learning Rate =  0.05  test_accuracy =  0.474025974025974\n",
      "Learning Rate =  0.06  test_accuracy =  0.474025974025974\n",
      "Learning Rate =  0.001  test_accuracy =  0.44805194805194803\n",
      "Learning Rate =  0.0001  test_accuracy =  0.33116883116883117\n"
     ]
    }
   ],
   "source": [
    "# 2. Learning Rate\n",
    "np.random.seed(0)\n",
    "weights = np.random.uniform(low = -1, high = 1, size=8).reshape(-1,1)\n",
    "for learning_rate in [0.1,0.01,0.02,0.028,0.029,0.03,0.033,0.035,0.037,0.04,0.05,0.06,0.001,0.0001]:\n",
    "    perceptron = Perceptron(\n",
    "        file_path='diabetes_scale.txt',\n",
    "        weights=weights, \n",
    "        loss_function_name=\"zero_one_loss\", \n",
    "        learning_rate=learning_rate, \n",
    "        epoch=10)\n",
    "    X, y = perceptron.get_features_labels_from_file_data()\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = perceptron.split_train_validation_test(X, y)\n",
    "    train_data = perceptron.train(X_train, y_train, X_val, y_val)\n",
    "    test_accuracy = perceptron.accuracy(X_test, y_test)\n",
    "    print('Learning Rate = ', learning_rate, ' test_accuracy = ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =  10  test_accuracy =  0.7337662337662337\n",
      "Epoch =  20  test_accuracy =  0.6948051948051948\n",
      "Epoch =  30  test_accuracy =  0.7662337662337663\n",
      "Epoch =  40  test_accuracy =  0.6688311688311688\n",
      "Epoch =  50  test_accuracy =  0.6688311688311688\n",
      "Epoch =  60  test_accuracy =  0.7922077922077922\n",
      "Epoch =  70  test_accuracy =  0.7662337662337663\n",
      "Epoch =  80  test_accuracy =  0.6688311688311688\n",
      "Epoch =  90  test_accuracy =  0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "# 3. Epoch\n",
    "np.random.seed(0)\n",
    "weights = np.random.uniform(low = -1, high = 1, size=8).reshape(-1,1)\n",
    "for epoch in range(10, 100, 10):\n",
    "    perceptron = Perceptron(\n",
    "        file_path='diabetes_scale.txt',\n",
    "        weights=weights, \n",
    "        loss_function_name=\"zero_one_loss\", \n",
    "        learning_rate=0.029, \n",
    "        epoch=epoch)\n",
    "    X, y = perceptron.get_features_labels_from_file_data()\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = perceptron.split_train_validation_test(X, y)\n",
    "    train_data = perceptron.train(X_train, y_train, X_val, y_val)\n",
    "    test_accuracy = perceptron.accuracy(X_test, y_test)\n",
    "    print('Epoch = ', epoch, ' test_accuracy = ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight =  (-1, 1)  test_accuracy =  0.7922077922077922\n",
      "Weight =  (0, 1)  test_accuracy =  0.6688311688311688\n",
      "Weight =  (-2, 2)  test_accuracy =  0.7857142857142857\n",
      "Weight =  (-0.5, 0.5)  test_accuracy =  0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "# 4. Weights\n",
    "# low,high pair\n",
    "weights_pairs = [(-1,1), (0,1), (-2,2),(-0.5,0.5)]\n",
    "np.random.seed(0)\n",
    "for weight_pair in weights_pairs:\n",
    "    low, high = weight_pair\n",
    "    weights = np.random.uniform(low=low, high = high, size=8).reshape(-1,1)\n",
    "    perceptron = Perceptron(\n",
    "        file_path='diabetes_scale.txt',\n",
    "        weights=weights, \n",
    "        loss_function_name=\"zero_one_loss\", \n",
    "        learning_rate=0.029, \n",
    "        epoch=60)\n",
    "    X, y = perceptron.get_features_labels_from_file_data()\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = perceptron.split_train_validation_test(X, y)\n",
    "    train_data = perceptron.train(X_train, y_train, X_val, y_val)\n",
    "    test_accuracy = perceptron.accuracy(X_test, y_test)\n",
    "    print('Weight = ', weight_pair, ' test_accuracy = ', test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b5451533b344355a501597b588174e3182b6d0803b6c4a8ab339d901650e8cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
