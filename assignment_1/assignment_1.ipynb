{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 1: Predict diabetes using Perceptron\n",
    "Student: Pujan Maharjan (a1863495)\n",
    "Course: Deep Learning Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# !pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Perceptron():\n",
    "    def __init__(self, \n",
    "        file_path, \n",
    "        weights, \n",
    "        loss_function_name, \n",
    "        learning_rate, \n",
    "        epoch,\n",
    "        add_bias = False) -> None:\n",
    "        self.file_path = file_path\n",
    "        self.weights = weights\n",
    "        self.loss_function_name = loss_function_name\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.add_bias = add_bias\n",
    "\n",
    "    def get_features_labels_from_file_data(self):\n",
    "        X, y = load_svmlight_file(self.file_path)\n",
    "        # convert X from scipy.sparce.csr.csr_matrix to numpy array\n",
    "        X = X.toarray()\n",
    "        # reshape y from (768,) to (768,1)\n",
    "        y = y.reshape(-1, 1)\n",
    "        return X,y\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(np.dot(X, self.weights))\n",
    "\n",
    "    def zero_one_loss(self, X, y):\n",
    "        xw = np.dot(X, self.weights)\n",
    "        losses = []\n",
    "        # if correct prediction, then loss = 0, else loss = 1\n",
    "        for i in range(len(y)):\n",
    "            indicator = y[i] * xw[i]\n",
    "            if indicator < 0:\n",
    "                losses.append(1)\n",
    "            else:\n",
    "                losses.append(0)\n",
    "\n",
    "        return np.array(losses).reshape(-1,1)\n",
    "\n",
    "    def add_bias_in_features(self, X_for_bias):\n",
    "        bias_X = np.ones((X_for_bias.shape[0],1))\n",
    "        X_for_bias = np.append(bias_X, X_for_bias, axis=1)\n",
    "        return X_for_bias\n",
    "        \n",
    "    def train(self, X_train, y_train, X_val, y_val):\n",
    "        train_data = []\n",
    "        if self.add_bias:\n",
    "            X_train = self.add_bias_in_features(X_train)\n",
    "            X_val = self.add_bias_in_features(X_val)\n",
    "            bias_value = np.random.uniform(low=-.1,high=.1, size=1)\n",
    "            print('Bias Value ', bias_value)\n",
    "            bias_W = np.array([bias_value])\n",
    "            # print('Shape of weights before bias ', self.weights.shape)\n",
    "            self.weights = np.append(bias_W, self.weights, axis=0)\n",
    "            # print('New shape of Weights : ', self.weights.shape)\n",
    "\n",
    "        for epoch_number in range(self.epoch):\n",
    "            # print('Epoch number: ', epoch_number)\n",
    "            train_loss = None\n",
    "            validation_loss = None\n",
    "            train_accuracy = None\n",
    "            if (self.loss_function_name == \"zero_one_loss\"):\n",
    "                train_loss = self.zero_one_loss(X_train, y_train)\n",
    "                validation_loss = self.zero_one_loss(X_val, y_val)\n",
    "                \n",
    "                # xl = X_train * train_loss               \n",
    "                # yxl = y_train * xl                \n",
    "                yxlr = self.learning_rate * y_train * X_train * train_loss           \n",
    "                yxlr_sum = np.sum(yxlr, axis=0).reshape(-1,1)                \n",
    "                self.weights = self.weights + yxlr_sum                \n",
    "                train_accuracy = self.accuracy(X_train, y_train)\n",
    "                \n",
    "            validation_accuracy = self.accuracy(X_val, y_val)\n",
    "            # print('Epoch ', epoch_number, ', Val accuracy: ', validation_accuracy)\n",
    "            train_data.append({\n",
    "                'learning_rate': self.learning_rate, \n",
    "                'epoch': epoch_number, \n",
    "                'train_loss': np.sum(train_loss), \n",
    "                'validation_loss': np.sum(validation_loss),\n",
    "                'validation_accuracy': validation_accuracy,\n",
    "                'train_accuracy': train_accuracy})\n",
    "\n",
    "        # print('Training Completed')\n",
    "        return train_data\n",
    "\n",
    "    def accuracy(self, X_accuracy, y_accuracy):\n",
    "        predictions_for_accuracy = self.predict(X_accuracy)\n",
    "        accuracy_score_from_sk_learn = accuracy_score(y_accuracy, predictions_for_accuracy)\n",
    "        return accuracy_score_from_sk_learn\n",
    "\n",
    "    def split_train_validation_test(self, X, y):\n",
    "        # reference to split (train/validation/test):\n",
    "        #  https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "            test_size=0.2, \n",
    "            random_state=1, \n",
    "            shuffle=True,\n",
    "            # stratify=y\n",
    "            )\n",
    "        # 0.25 * 0.8 = 0.2\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "            test_size=0.25, \n",
    "            random_state=1, \n",
    "            shuffle=True,\n",
    "            # stratify=y_train\n",
    "            )\n",
    "\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File =  diabetes_scale.txt  test_accuracy =  0.6493506493506493\n",
      "File =  diabetes.txt  test_accuracy =  0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "# 1. Different Files (Without scaling vs scaled)\n",
    "np.random.seed(0)\n",
    "# weights = np.random.uniform(low = -1, high = 1, size=8).reshape(-1,1)\n",
    "# weights = np.random.normal(size=8).reshape(-1,1)\n",
    "weights = np.random.rand(8,1)\n",
    "for file_path in ['diabetes_scale.txt','diabetes.txt']:\n",
    "    perceptron = Perceptron(\n",
    "        file_path=file_path,\n",
    "        weights=weights, \n",
    "        loss_function_name=\"zero_one_loss\", \n",
    "        learning_rate=0.01, \n",
    "        epoch=10)\n",
    "    X, y = perceptron.get_features_labels_from_file_data()\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = perceptron.split_train_validation_test(X, y)\n",
    "    train_data = perceptron.train(X_train, y_train, X_val, y_val)\n",
    "    test_accuracy = perceptron.accuracy(X_test, y_test)\n",
    "    print('File = ', file_path, ' test_accuracy = ', test_accuracy)\n",
    "    # train_data_pd = pd.DataFrame(train_data)\n",
    "    # print(train_data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias Value  [0.09273255]\n",
      "File =  diabetes_scale.txt  test_accuracy =  0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "# 1. Different Files (Without scaling vs scaled)\n",
    "np.random.seed(0)\n",
    "# weights = np.random.uniform(low = -1, high = 1, size=8).reshape(-1,1)\n",
    "# weights = np.random.normal(size=8).reshape(-1,1)\n",
    "weights = np.random.rand(8,1)\n",
    "for file_path in ['diabetes_scale.txt']:\n",
    "    perceptron = Perceptron(\n",
    "        file_path=file_path,\n",
    "        weights=weights, \n",
    "        loss_function_name=\"zero_one_loss\", \n",
    "        learning_rate=0.01, \n",
    "        epoch=10,\n",
    "        add_bias=True)\n",
    "    X, y = perceptron.get_features_labels_from_file_data()\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = perceptron.split_train_validation_test(X, y)\n",
    "    train_data = perceptron.train(X_train, y_train, X_val, y_val)\n",
    "    X_test = perceptron.add_bias_in_features(X_test)\n",
    "    test_accuracy = perceptron.accuracy(X_test, y_test)\n",
    "    print('File = ', file_path, ' test_accuracy = ', test_accuracy)\n",
    "    # train_data_pd = pd.DataFrame(train_data)\n",
    "    # print(train_data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate =  0.1  test_accuracy =  0.6493506493506493\n",
      "Learning Rate =  0.01  test_accuracy =  0.6493506493506493\n",
      "Learning Rate =  0.02  test_accuracy =  0.6818181818181818\n",
      "Learning Rate =  0.028  test_accuracy =  0.7272727272727273\n",
      "Learning Rate =  0.029  test_accuracy =  0.7727272727272727\n",
      "Learning Rate =  0.03  test_accuracy =  0.7012987012987013\n",
      "Learning Rate =  0.033  test_accuracy =  0.6883116883116883\n",
      "Learning Rate =  0.035  test_accuracy =  0.6883116883116883\n",
      "Learning Rate =  0.037  test_accuracy =  0.6883116883116883\n",
      "Learning Rate =  0.04  test_accuracy =  0.6948051948051948\n",
      "Learning Rate =  0.05  test_accuracy =  0.6883116883116883\n",
      "Learning Rate =  0.06  test_accuracy =  0.564935064935065\n",
      "Learning Rate =  0.001  test_accuracy =  0.43506493506493504\n",
      "Learning Rate =  0.0001  test_accuracy =  0.3051948051948052\n"
     ]
    }
   ],
   "source": [
    "# 2. Learning Rate\n",
    "np.random.seed(0)\n",
    "# weights = np.random.uniform(low = -1, high = 1, size=8).reshape(-1,1)\n",
    "# weights = np.random.normal(size=8).reshape(-1,1)\n",
    "weights = np.random.rand(8,1)\n",
    "for learning_rate in [0.1,0.01,0.02,0.028,0.029,0.03,0.033,0.035,0.037,0.04,0.05,0.06,0.001,0.0001]:\n",
    "    perceptron = Perceptron(\n",
    "        file_path='diabetes_scale.txt',\n",
    "        weights=weights, \n",
    "        loss_function_name=\"zero_one_loss\", \n",
    "        learning_rate=learning_rate, \n",
    "        epoch=10)\n",
    "    X, y = perceptron.get_features_labels_from_file_data()\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = perceptron.split_train_validation_test(X, y)\n",
    "    train_data = perceptron.train(X_train, y_train, X_val, y_val)\n",
    "    test_accuracy = perceptron.accuracy(X_test, y_test)\n",
    "    print('Learning Rate = ', learning_rate, ' test_accuracy = ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =  10  test_accuracy =  0.7727272727272727\n",
      "Epoch =  20  test_accuracy =  0.6623376623376623\n",
      "Epoch =  30  test_accuracy =  0.6623376623376623\n",
      "Epoch =  40  test_accuracy =  0.6688311688311688\n",
      "Epoch =  50  test_accuracy =  0.7402597402597403\n",
      "Epoch =  60  test_accuracy =  0.7727272727272727\n",
      "Epoch =  70  test_accuracy =  0.7272727272727273\n",
      "Epoch =  80  test_accuracy =  0.7987012987012987\n",
      "Epoch =  90  test_accuracy =  0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "# 3. Epoch\n",
    "np.random.seed(0)\n",
    "# weights = np.random.uniform(low = -1, high = 1, size=8).reshape(-1,1)\n",
    "# weights = np.random.normal(size=8).reshape(-1,1)\n",
    "weights = np.random.rand(8,1)\n",
    "for epoch in range(10, 100, 10):\n",
    "    perceptron = Perceptron(\n",
    "        file_path='diabetes_scale.txt',\n",
    "        weights=weights, \n",
    "        loss_function_name=\"zero_one_loss\", \n",
    "        learning_rate=0.029, \n",
    "        epoch=epoch)\n",
    "    X, y = perceptron.get_features_labels_from_file_data()\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = perceptron.split_train_validation_test(X, y)\n",
    "    train_data = perceptron.train(X_train, y_train, X_val, y_val)\n",
    "    test_accuracy = perceptron.accuracy(X_test, y_test)\n",
    "    print('Epoch = ', epoch, ' test_accuracy = ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight =  (-1, 1)  test_accuracy =  0.7987012987012987\n",
      "Weight =  (0, 1)  test_accuracy =  0.7337662337662337\n",
      "Weight =  (-2, 2)  test_accuracy =  0.7922077922077922\n",
      "Weight =  (-0.5, 0.5)  test_accuracy =  0.7337662337662337\n",
      "Weight =  (0, 0)  test_accuracy =  0.7987012987012987\n"
     ]
    }
   ],
   "source": [
    "# 4. Weights\n",
    "# low,high pair\n",
    "#  [(-1,1), (0,1), (-2,2),(-0.5,0.5),(0,0)]\n",
    "weights_pairs = [(-1,1), (0,1), (-2,2),(-0.5,0.5),(0,0)]\n",
    "np.random.seed(0)\n",
    "for weight_pair in weights_pairs:\n",
    "    low, high = weight_pair\n",
    "    # weights = np.random.uniform(low=low, high = high, size=8).reshape(-1,1)\n",
    "    # weights = np.random.normal(size=8).reshape(-1,1)\n",
    "    weights = np.random.rand(8,1)\n",
    "    perceptron = Perceptron(\n",
    "        file_path='diabetes_scale.txt',\n",
    "        weights=weights, \n",
    "        loss_function_name=\"zero_one_loss\", \n",
    "        learning_rate=0.029, \n",
    "        epoch=80)\n",
    "    X, y = perceptron.get_features_labels_from_file_data()\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = perceptron.split_train_validation_test(X, y)\n",
    "    train_data = perceptron.train(X_train, y_train, X_val, y_val)\n",
    "    test_accuracy = perceptron.accuracy(X_test, y_test)\n",
    "    print('Weight = ', weight_pair, ' test_accuracy = ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.random.uniform(low=0, high = 0, size=8).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  (2, 3) , a: \n",
      "\n",
      "b shape:  (2, 1) , b: \n",
      " [[1.]\n",
      " [1.]]\n",
      "x shape:  (2, 4) , c = \n",
      " [[1. 1. 2. 3.]\n",
      " [1. 2. 3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2,3],[2,3,4]])\n",
    "print('x shape: ', x.shape, ', a: \\n')\n",
    "\n",
    "b = np.ones((x.shape[0],1))\n",
    "print('b shape: ', b.shape, ', b: \\n', b)\n",
    "\n",
    "x = np.append(b, x, axis=1)\n",
    "print('x shape: ', x.shape, ', c = \\n', x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  (3, 1) , x: \n",
      " (3, 1)\n",
      "b1 shape:  (1, 1) , b: \n",
      " [[1]]\n",
      "x shape:  (4, 1) , c = \n",
      " [[1]\n",
      " [1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([[1],[2],[3]])\n",
    "print('x shape: ', x1.shape, ', x: \\n', x1.shape)\n",
    "\n",
    "b1 = np.array([[1]])\n",
    "print('b1 shape: ', b1.shape, ', b: \\n', b1)\n",
    "\n",
    "x1 = np.append(b1, x1, axis=0)\n",
    "print('x shape: ', x1.shape, ', c = \\n', x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0097627]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "print(np.random.uniform(low=-.1,high=.1, size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File =  diabetes_scale.txt  test_accuracy =  0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "# 1. Different Files (Without scaling vs scaled)\n",
    "np.random.seed(0)\n",
    "# weights = np.random.uniform(low = -1, high = 1, size=8).reshape(-1,1)\n",
    "# weights = np.random.normal(size=8).reshape(-1,1)\n",
    "weights = np.random.rand(8,1)\n",
    "for file_path in ['diabetes_scale.txt']:\n",
    "    perceptron = Perceptron(\n",
    "        file_path=file_path,\n",
    "        weights=weights, \n",
    "        loss_function_name=\"zero_one_loss\", \n",
    "        learning_rate=0.029, \n",
    "        epoch=60)\n",
    "    X, y = perceptron.get_features_labels_from_file_data()\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = perceptron.split_train_validation_test(X, y)\n",
    "    train_data = perceptron.train(X_train, y_train, X_val, y_val)\n",
    "    test_accuracy = perceptron.accuracy(X_test, y_test)\n",
    "    print('File = ', file_path, ' test_accuracy = ', test_accuracy)\n",
    "    # train_data_pd = pd.DataFrame(train_data)\n",
    "    # print(train_data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias Value  [0.09273255]\n",
      "File =  diabetes_scale.txt  test_accuracy =  0.8051948051948052\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "# 1. Different Files (Without scaling vs scaled)\n",
    "np.random.seed(0)\n",
    "# weights = np.random.uniform(low = -1, high = 1, size=8).reshape(-1,1)\n",
    "# weights = np.random.normal(size=8).reshape(-1,1)\n",
    "weights = np.random.rand(8,1)\n",
    "for file_path in ['diabetes_scale.txt']:\n",
    "    perceptron = Perceptron(\n",
    "        file_path=file_path,\n",
    "        weights=weights, \n",
    "        loss_function_name=\"zero_one_loss\", \n",
    "        learning_rate=0.029, \n",
    "        epoch=60,\n",
    "        add_bias=True)\n",
    "    X, y = perceptron.get_features_labels_from_file_data()\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = perceptron.split_train_validation_test(X, y)\n",
    "    train_data = perceptron.train(X_train, y_train, X_val, y_val)\n",
    "    X_test = perceptron.add_bias_in_features(X_test)\n",
    "    test_accuracy = perceptron.accuracy(X_test, y_test)\n",
    "    print('File = ', file_path, ' test_accuracy = ', test_accuracy)\n",
    "    # train_data_pd = pd.DataFrame(train_data)\n",
    "    # print(train_data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235],\n",
       "       [ 0.40015721],\n",
       "       [ 0.97873798],\n",
       "       [ 2.2408932 ],\n",
       "       [ 1.86755799],\n",
       "       [-0.97727788],\n",
       "       [ 0.95008842],\n",
       "       [-0.15135721]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "weights = np.random.normal(size=8).reshape(-1,1)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5488135 ],\n",
       "       [0.71518937],\n",
       "       [0.60276338],\n",
       "       [0.54488318],\n",
       "       [0.4236548 ],\n",
       "       [0.64589411],\n",
       "       [0.43758721],\n",
       "       [0.891773  ]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "weights = np.random.rand(8,1)\n",
    "weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b5451533b344355a501597b588174e3182b6d0803b6c4a8ab339d901650e8cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
