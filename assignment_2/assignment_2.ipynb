{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-4xgT39sQUj"
      },
      "source": [
        "Deep Learning Assignment 2 Pujan\n",
        "\n",
        "code reference: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "w4s_pul2sQUm"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_device():\n",
        "    return torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# print(\"Device is \",get_device())\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def get_output_width(input_width, filter_size, padding, stride):\n",
        "    return ((input_width - filter_size + 2 * padding)/stride) + 1\n",
        "\n",
        "print(get_output_width(input_width = 32, filter_size = 5, padding = 0, stride = 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L4vTpqntB_Q",
        "outputId": "bea2f772-285a-408b-b10b-6077e0d67193"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PujanNet(nn.Module):\n",
        "    def __init__(self, data_set_name, batch_size, download_path, train_data_size, validation_data_size, criterion):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(5)\n",
        "        self.train_results = []\n",
        "        self.epoch_number = 0\n",
        "    \n",
        "        transform = transforms.Compose(\n",
        "            [\n",
        "                #transforms.Grayscale(num_output_channels=3), # with grayscale, overfitting slightly decreased, this should be the result of data augmentation, this is not converting all images to grayscale\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "            ])\n",
        "\n",
        "        if data_set_name == \"cifar_10\":\n",
        "            dataset = torchvision.datasets.CIFAR10(root=download_path, train=True, download=True, transform=transform)\n",
        "            print('Length of Dataset ', len(dataset))\n",
        "\n",
        "            train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_data_size, validation_data_size])\n",
        "            print('Length of Train set ', len(train_dataset))\n",
        "            print('Length of Val set ', len(val_dataset))\n",
        "            self.trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "            self.valloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "            testset = torchvision.datasets.CIFAR10(root=download_path, train=False, download=True, transform=transform)\n",
        "            print('Length of Testset ', len(testset))\n",
        "            self.testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "            self.classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "        self.criterion = criterion\n",
        "        # input channel should be 3 for color image and 1 for grayscale\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        # self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def display_input_images(self, number_of_images):\n",
        "        # get some random training images\n",
        "        dataiter = iter(self.trainloader)\n",
        "        images, labels = dataiter.next()\n",
        "\n",
        "        # show images\n",
        "        imshow(torchvision.utils.make_grid(images))\n",
        "        # print labels\n",
        "        print(' '.join(f'{self.classes[labels[j]]:5s}' for j in range(number_of_images)))\n",
        "\n",
        "    def display_ground_truth_images(self, number_of_images):\n",
        "        dataiter = iter(self.testloader)\n",
        "        images, labels = dataiter.next()\n",
        "\n",
        "        # print images\n",
        "        imshow(torchvision.utils.make_grid(images))\n",
        "        print('GroundTruth: ', ' '.join(f'{self.classes[labels[j]]:5s}' for j in range(4)))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"Initial x shape \", x.shape)\n",
        "        # x = self.pool(F.relu(self.conv1(x)))\n",
        "        # print(\"After conv1 and maxpool, x shape \", x.shape)\n",
        "\n",
        "        # First layer\n",
        "        x = F.relu(self.conv1(x))\n",
        "        print('After conv1, shape of x is ', x.shape)\n",
        "        x = self.pool(x)\n",
        "        print('After max pool 1, shape of x is ', x.shape)\n",
        "        \n",
        "        # Second layer\n",
        "        # x = self.pool(F.relu(self.conv2(x)))\n",
        "        # print(\"After conv2 and maxpool, x shape \", x.shape)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        print('After conv2, shape of X is ', x.shape)\n",
        "        x = self.pool(x)\n",
        "        print('After max pool 2, shape of x is ', x.shape)\n",
        "\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        print('After flatten, x shape ', x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        print('After fc1, x shape ', x.shape)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        print('After fc2, x shape ', x.shape)\n",
        "        x = self.fc3(x)\n",
        "        print('After fc3, x shape ', x.shape)\n",
        "        break_here_i_want_to_see_shapes\n",
        "        return x\n",
        "\n",
        "    def train(self, epoch_number, learning_rate, momentum, optimizer_name):\n",
        "        optimizer = optim.SGD(self.parameters(), lr= learning_rate, momentum=momentum)\n",
        "        # if optimizer_name == \"sgd\": \n",
        "        self.epoch_number = epoch_number\n",
        "        train_results = []\n",
        "\n",
        "        for epoch in range(epoch_number):  # loop over the dataset multiple times\n",
        "            # Training phase\n",
        "            running_loss = 0.0\n",
        "            train_losses = []\n",
        "            train_accuracies = []\n",
        "            for i, train_data in enumerate(self.trainloader, 0):\n",
        "                # get the inputs; data is a list of [inputs, labels]\n",
        "                train_inputs, train_labels = train_data[0].to(get_device()), train_data[1].to(get_device())\n",
        "                \n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward + backward + optimize\n",
        "                train_outputs = self(train_inputs)\n",
        "                train_loss = self.criterion(train_outputs, train_labels)\n",
        "                train_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss_item = train_loss.item()\n",
        "                train_losses.append(train_loss_item)\n",
        "                accuracy_score_batch = self.get_accuracy_score(train_outputs, train_labels)\n",
        "                train_accuracies.append(accuracy_score_batch)\n",
        "                # print statistics\n",
        "                running_loss += train_loss_item\n",
        "                # if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                #     print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "                #     running_loss = 0.0\n",
        "\n",
        "            train_loss_epoch = np.mean(train_losses)\n",
        "            train_accuracy, train_loss_value = self.get_accuracy_and_loss(self.trainloader)\n",
        "\n",
        "            val_accuracy, val_loss_value = self.get_accuracy_and_loss(self.valloader)\n",
        "\n",
        "            train_result = {'epoch': epoch, 'train_loss': train_loss_value, 'train_accuracy': train_accuracy, \n",
        "                                  'val_loss': val_loss_value, 'val_accuracy': val_accuracy}\n",
        "            print('Train result ', train_result)\n",
        "            train_results.append(train_result)\n",
        "\n",
        "        print('Finished Training')\n",
        "        self.train_results = train_results\n",
        "        return train_results\n",
        "\n",
        "    def plot_loss_and_accuracy_curves(self):\n",
        "        epoch_numbers = range(self.epoch_number)\n",
        "        # loss curves : train / val\n",
        "        # accuracy curves: train / val\n",
        " \n",
        "        # accuracy curve    \n",
        "        train_accuracies = [x['train_accuracy'] for x in self.train_results]\n",
        "        val_accuracies = [x['val_accuracy'] for x in self.train_results]    \n",
        "        plt.plot(train_accuracies, label=\"train\")\n",
        "        plt.plot(val_accuracies, label=\"val\")\n",
        "        plt.legend()\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(\"Accuracy vs Epoch\")\n",
        "        plt.show()\n",
        "\n",
        "        # Loss curve    \n",
        "        train_losses = [x['train_loss'] for x in self.train_results]\n",
        "        val_losses = [x['val_loss'] for x in self.train_results]    \n",
        "        plt.plot(train_losses, label=\"train\")\n",
        "        plt.plot(val_losses, label=\"val\")\n",
        "        plt.legend()\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(\"Loss vs Epoch\")\n",
        "        plt.show()\n",
        "\n",
        "    # def get_loss(self, data_loader):\n",
        "    #     val_losses = []\n",
        "    #     with torch.no_grad():\n",
        "    #         for data in data_loader:\n",
        "    #             inputs, labels = data[0].to(get_device()), data[1].to(get_device())\n",
        "    #             outputs = self(inputs)\n",
        "    #             loss = self.criterion(outputs, labels)\n",
        "    #             loss_item = loss.item()\n",
        "    #             val_losses.append(loss_item)\n",
        "\n",
        "    #     val_loss_mean = np.mean(val_losses)\n",
        "    #     return val_loss_mean\n",
        "\n",
        "\n",
        "    def predictions(self, input_images):\n",
        "        outputs = self(input_images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        print('Predicted: ', ' '.join(f'{self.classes[predicted[j]]:5s}' for j in range(4)))\n",
        "\n",
        "    def get_accuracy_score(self, outputs, labels):\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        return correct\n",
        "\n",
        "    def get_accuracy_and_loss(self, data_loader):\n",
        "        accuracies = []\n",
        "        loss_values = []\n",
        "        total_label_size = 0\n",
        "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "        with torch.no_grad():\n",
        "            for data in data_loader:\n",
        "                # images, labels = data\n",
        "                images, labels = data[0].to(get_device()), data[1].to(get_device())\n",
        "                # calculate outputs by running images through the network\n",
        "                outputs = self(images)\n",
        "                # the class with the highest energy is what we choose as prediction\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total_label_size += labels.size(0)\n",
        "                accuracy_item = (predicted == labels).sum().item()\n",
        "                accuracies.append(accuracy_item)\n",
        "\n",
        "                # losses\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss_item = loss.item()\n",
        "                loss_values.append(loss_item)\n",
        "        \n",
        "        accuracy_score = 100 * np.sum(accuracies) / total_label_size\n",
        "        loss_value = np.mean(loss_values)\n",
        "        return (accuracy_score, loss_value)\n",
        "\n",
        "    def accuracy_in_each_class(self):\n",
        "    # prepare to count predictions for each class\n",
        "        correct_pred = {classname: 0 for classname in self.classes}\n",
        "        total_pred = {classname: 0 for classname in self.classes}\n",
        "\n",
        "        # again no gradients needed\n",
        "        with torch.no_grad():\n",
        "            for data in self.testloader:\n",
        "                # images, labels = data\n",
        "                images, labels = data[0].to(get_device()), data[1].to(get_device())\n",
        "                outputs = self(images)\n",
        "                _, predictions = torch.max(outputs, 1)\n",
        "                # collect the correct predictions for each class\n",
        "                for label, prediction in zip(labels, predictions):\n",
        "                    if label == prediction:\n",
        "                        correct_pred[self.classes[label]] += 1\n",
        "                    total_pred[self.classes[label]] += 1\n",
        "\n",
        "        # print accuracy for each class\n",
        "        for classname, correct_count in correct_pred.items():\n",
        "            accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "            print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FKedomWmtUGv"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "pujan_net = PujanNet(data_set_name = \"cifar_10\", batch_size = 4, download_path = \"./data\", \n",
        "                     train_data_size = 40000, validation_data_size = 10000, criterion = criterion)\n",
        "pujan_net = pujan_net.to(get_device())\n",
        "\n",
        "train_results = pujan_net.train(epoch_number = 1, learning_rate = 0.001, momentum = 0.9, optimizer_name = \"sgd\")\n",
        "pujan_net.plot_loss_and_accuracy_curves()\n",
        "# print(train_results)\n",
        "# pujan_net.accuracy(pujan_net.testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "2RR5qjAVtgzf",
        "outputId": "6e4fd2bc-8cda-47aa-bffc-7689c6998e15"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Length of Dataset  50000\n",
            "Length of Train set  40000\n",
            "Length of Val set  10000\n",
            "Files already downloaded and verified\n",
            "Length of Testset  10000\n",
            "Initial x shape  torch.Size([4, 3, 32, 32])\n",
            "After conv1, shape of x is  torch.Size([4, 6, 28, 28])\n",
            "After max pool 1, shape of x is  torch.Size([4, 6, 14, 14])\n",
            "After conv2, shape of X is  torch.Size([4, 16, 10, 10])\n",
            "After max pool 2, shape of x is  torch.Size([4, 16, 5, 5])\n",
            "After flatten, x shape  torch.Size([4, 400])\n",
            "After fc1, x shape  torch.Size([4, 120])\n",
            "After fc2, x shape  torch.Size([4, 84])\n",
            "After fc3, x shape  torch.Size([4, 10])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-fb588ce75b2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpujan_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpujan_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpujan_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sgd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mpujan_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_loss_and_accuracy_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# print(train_results)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-ee5a2d47b00c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch_number, learning_rate, momentum, optimizer_name)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mtrain_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-ee5a2d47b00c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'After fc3, x shape '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mbreak_here_i_want_to_see_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'break_here_i_want_to_see_shapes' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiments\n",
        "# Pre processing: Convert into grayscale, since our objective is classification, we don't need  color too,\n",
        "# try with grayscale image\n",
        "# Post processing: pooling: Max pooling, average pooling, min pooling. But, practically, max pooling was found to be better by many researchers\n",
        "\n",
        "\n",
        "# selecting the model\n",
        "# CNN Architectures (How to choose CNN architecture ????)\n",
        "# Number of Layers ??\n",
        "# Batch Normalization\n",
        "# Dropout\n",
        "\n",
        "# Input data enhancements\n",
        "# Data augmentation\n",
        "\n",
        "# Hyper parameters\n",
        "# Loss\n",
        "# Optimizer\n",
        "# Epoch\n",
        "# Learning rate\n",
        "# Batch size\n",
        "\n"
      ],
      "metadata": {
        "id": "iJDaeTxz84-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jenw8USp7rb1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}